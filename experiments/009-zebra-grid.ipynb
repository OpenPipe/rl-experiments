{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 64, 64, 872)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from lib.zebra_grid import get_zebra_grid_tasks\n",
    "from lib.tasks import ChatCompletionParams, get_task_results\n",
    "import openai\n",
    "import os\n",
    "\n",
    "zebra_grid_tasks = list(get_zebra_grid_tasks())\n",
    "benchmark_tasks = zebra_grid_tasks[:80]\n",
    "val_tasks = zebra_grid_tasks[:64]\n",
    "test_tasks = zebra_grid_tasks[64:128]\n",
    "train_tasks = zebra_grid_tasks[128:]\n",
    "len(benchmark_tasks), len(val_tasks), len(test_tasks), len(train_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808609b2c6a3499b9c16e9127cfd1e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "deepseek-r1:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a866c2bf98e4353832781e841d59273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "r1-qwen-1.5b:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb4628709c7494e962a0d025924fb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "qwen-2.5-7b:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f146fbaf5fb4eddb6ee7d5b1f7c4abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "r1-qwen-14b:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a976d7cd714bd0886b523acb4ad097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "r1-qwen-32b:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d357d1559814a7caa82d617bf22ab28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "r1-llama-70b:targon:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba4f74c2429475a9201f34d2b7917ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "r1-llama-70b:samba:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fireworks = openai.AsyncOpenAI(\n",
    "    base_url=\"https://api.fireworks.ai/inference/v1\",\n",
    "    api_key=os.getenv(\"FIREWORKS_API_KEY\"),\n",
    ")\n",
    "openrouter = openai.AsyncOpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\", api_key=os.getenv(\"OPENROUTER_API_KEY\")\n",
    ")\n",
    "together = openai.AsyncOpenAI(\n",
    "    base_url=\"https://api.together.xyz/v1\", api_key=os.getenv(\"TOGETHER_API_KEY\")\n",
    ")\n",
    "\n",
    "results = await asyncio.gather(\n",
    "    get_task_results(\n",
    "        tasks=benchmark_tasks,\n",
    "        client=fireworks,\n",
    "        model=\"accounts/fireworks/models/deepseek-r1\",\n",
    "        params=ChatCompletionParams(\n",
    "            max_tokens=2**17,\n",
    "            logprobs=True,\n",
    "            top_logprobs=5,\n",
    "        ),\n",
    "        pbar_desc=\"deepseek-r1\",\n",
    "        prices=(8.0, 8.0),\n",
    "    ),\n",
    "    get_task_results(\n",
    "        tasks=benchmark_tasks,\n",
    "        client=openrouter,\n",
    "        model=\"deepseek/deepseek-r1-distill-qwen-1.5b\",\n",
    "        pbar_desc=\"r1-qwen-1.5b\",\n",
    "        prices=(0.18, 0.18),\n",
    "    ),\n",
    "    get_task_results(\n",
    "        tasks=benchmark_tasks,\n",
    "        client=openrouter,\n",
    "        model=\"qwen/qwen-2.5-7b-instruct\",\n",
    "        pbar_desc=\"qwen-2.5-7b\",\n",
    "        params=ChatCompletionParams(\n",
    "            extra_body={\"provider\": {\"order\": [\"DeepInfra\"], \"allow_fallbacks\": False}},\n",
    "        ),\n",
    "        prices=(0.0025, 0.005),\n",
    "    ),\n",
    "    get_task_results(\n",
    "        tasks=benchmark_tasks,\n",
    "        client=openrouter,\n",
    "        model=\"deepseek/deepseek-r1-distill-qwen-14b\",\n",
    "        pbar_desc=\"r1-qwen-14b\",\n",
    "        prices=(1.6, 1.6),\n",
    "    ),\n",
    "    get_task_results(\n",
    "        tasks=benchmark_tasks,\n",
    "        client=openrouter,\n",
    "        model=\"deepseek/deepseek-r1-distill-qwen-32b\",\n",
    "        params=ChatCompletionParams(\n",
    "            extra_body={\"provider\": {\"order\": [\"DeepInfra\"], \"allow_fallbacks\": False}},\n",
    "        ),\n",
    "        pbar_desc=\"r1-qwen-32b\",\n",
    "        prices=(0.12, 0.18),\n",
    "    ),\n",
    "    get_task_results(\n",
    "        tasks=benchmark_tasks,\n",
    "        client=openrouter,\n",
    "        model=\"deepseek/deepseek-r1-distill-llama-70b:free\",\n",
    "        params=ChatCompletionParams(\n",
    "            extra_body={\"provider\": {\"order\": [\"Targon\"], \"allow_fallbacks\": False}},\n",
    "        ),\n",
    "        pbar_desc=\"r1-llama-70b:targon\",\n",
    "        prices=(0.0, 0.0),\n",
    "    ),\n",
    "    get_task_results(\n",
    "        tasks=benchmark_tasks,\n",
    "        client=openrouter,\n",
    "        model=\"deepseek/deepseek-r1-distill-llama-70b\",\n",
    "        params=ChatCompletionParams(\n",
    "            extra_body={\"provider\": {\"order\": [\"SambaNova\"], \"allow_fallbacks\": False}},\n",
    "        ),\n",
    "        pbar_desc=\"r1-llama-70b:samba\",\n",
    "        prices=(0.7, 1.4),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m [exception \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m exception \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mexceptions][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/github/bradhilton/openpipe-rl/experiments/lib/tasks.py:99\u001b[0m, in \u001b[0;36mget_task_results.<locals>.get_task_result\u001b[0;34m(task, client, model, log_results)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m reward_future \u001b[38;5;129;01min\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mas_completed(\n\u001b[1;32m     96\u001b[0m     _grade(choice, task\u001b[38;5;241m.\u001b[39mgrader) \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m chat_completion\u001b[38;5;241m.\u001b[39mchoices\n\u001b[1;32m     97\u001b[0m ):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m         choice_index, reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m reward_future\n\u001b[1;32m    100\u001b[0m         stats\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mchat_completion\u001b[38;5;241m.\u001b[39mid, reward\u001b[38;5;241m=\u001b[39mreward)\n\u001b[1;32m    101\u001b[0m         rewards[chat_completion\u001b[38;5;241m.\u001b[39mid, choice_index] \u001b[38;5;241m=\u001b[39m reward\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/tasks.py:631\u001b[0m, in \u001b[0;36mas_completed.<locals>._wait_for_one\u001b[0;34m()\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# Dummy value from _on_timeout().\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTimeoutError\n\u001b[0;32m--> 631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/bradhilton/openpipe-rl/experiments/lib/tasks.py:93\u001b[0m, in \u001b[0;36mget_task_results.<locals>.get_task_result.<locals>._grade\u001b[0;34m(choice, grader)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_grade\u001b[39m(choice: Choice, grader: Grader) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m choice\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28;01mawait\u001b[39;00m maybe_await(\u001b[43mgrader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchoice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/github/bradhilton/openpipe-rl/experiments/lib/zebra_grid.py:36\u001b[0m, in \u001b[0;36mget_zebra_grid_tasks.<locals>.grader\u001b[0;34m(choice, puzzle, pattern)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgrader\u001b[39m(\n\u001b[1;32m     31\u001b[0m     choice: Choice,\n\u001b[1;32m     32\u001b[0m     puzzle: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m puzzle,\n\u001b[1;32m     33\u001b[0m     pattern: re\u001b[38;5;241m.\u001b[39mPattern[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m pattern,\n\u001b[1;32m     34\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m     35\u001b[0m     content \u001b[38;5;241m=\u001b[39m choice\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m content \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     37\u001b[0m     num_cells \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(row) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m puzzle[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolution\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     38\u001b[0m     num_cells \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(row) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m puzzle[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolution\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise [exception for result in results[1][0] for exception in result.exceptions][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
